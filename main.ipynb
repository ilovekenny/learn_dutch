{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29209573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordlist import WordList\n",
    "from learner import MyLearner\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73677604",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = WordList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# Beautiful printing of the text\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "to_markdown(chat_completion.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the llm model\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import time\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "\n",
    "# read the api_key from a text file\n",
    "with open(\"var.txt\",\"r\") as f:\n",
    "    var = f.read()\n",
    "# connect to gemini model    \n",
    "genai.configure(api_key=var)\n",
    "model = genai.GenerativeModel('models/gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ingestion list from a text file\n",
    "with open('input3.txt', 'r') as f:\n",
    "    data = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58938451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a verified list from gemini\n",
    "prompt_text = \"\"\"\n",
    "Here is a list of dutch words and short phrases. Some of them are translated to english and russian, some only to english. \n",
    "Add missing translations of dutch words to english or to russian columns and return it in json format. Make sure that there \n",
    "are no missing or null translations in english or in russian. The json format should be the following:\n",
    "{'althans': {'english': 'at least', 'russian': 'по крайней мере'},\n",
    "'overleggen': {'english': 'to discuss', 'russian': 'обсуждать'},\n",
    "'het hoorcollege': {'english': 'lecture', 'russian': 'лекция'},\n",
    "}\n",
    "The words: \"\"\" \n",
    "chat_completion = model.generate_content(prompt_text + data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30079bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the list and convert it to json and then to 2d list\n",
    "\n",
    "import json\n",
    "raw_string = chat_completion.candidates[0].content.parts[0].text\n",
    "\n",
    "# 1. Clean up the Markdown code block wrappers\n",
    "clean_json = raw_string.strip().removeprefix('```json').removesuffix('```').strip()\n",
    "\n",
    "# 2. Parse it with json.loads()\n",
    "data = json.loads(clean_json)\n",
    "\n",
    "# 3. Convert it to a 2D lis\n",
    "words_list = []\n",
    "for dutch_word in data:\n",
    "    dutch = dutch_word\n",
    "    try:\n",
    "      english = data[dutch_word]['english']\n",
    "    except KeyError:\n",
    "       english = ''\n",
    "    try: \n",
    "      russian = data[dutch_word]['russian']\n",
    "    except KeyError:\n",
    "       russian = ''\n",
    "    words_list.append([dutch, english, russian]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b62d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest the list to the list\n",
    "a.ingest_list(words_list=words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d31740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "similarity = get_similarity(\"het geweld\", \"de geweld\")  # maybe 0.66\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47e48a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordlist import WordList\n",
    "import random\n",
    "import numpy as np\n",
    "class MyLearner:\n",
    "    def __init__(self, words_list:WordList):\n",
    "        self.status = 0\n",
    "        self.words_list = words_list\n",
    "        self.all_words= self.words_list.get_all_words()\n",
    "        self.n_list = len(self.words_list.get_all_words())\n",
    "        self.n_to_learn = 0\n",
    "        self.threshold0 = 0.3\n",
    "        self.threshold1 = 0.7\n",
    "        # Portion of words in each group\n",
    "        self.partition = [0.6, 0.3, 0.1]\n",
    "        self.ind0_sampled = [] # list of indeces of words with low score to be learned\n",
    "        self.ind1_sampled = [] # list of indeces of words with medium score to be learned\n",
    "        self.ind2_sampled = [] # list of indeces of words with high score to be learned\n",
    "        self.ind_sampled = [] # list of indeces of words with all score to be learned\n",
    "        self.task_list_with_options = []\n",
    "        self.score_list = [] # score list\n",
    "\n",
    "    def SelectWords(self,n:int=10):\n",
    "        # n, int, number of words to test\n",
    "        self.n_to_learn = n\n",
    "        self.score_list = [item['score'] for item in self.all_words]\n",
    "        sorted_indices = np.argsort(self.score_list)\n",
    "        # print(\"Sorted indices:\", sorted_indices)  # [1, 3, 0, 2]\n",
    "        # ind0 = [x for x in score_list if x < self.threshold0]\n",
    "        # get indeces of the words with different scores\n",
    "        ind0 = []\n",
    "        ind1 = []\n",
    "        ind2 = []\n",
    "        for i_x,x in enumerate(self.score_list):\n",
    "            if x < self.threshold0:\n",
    "                ind0.append(i_x)\n",
    "            elif (x >= self.threshold0 and x < self.threshold1):\n",
    "                ind1.append(i_x)\n",
    "            else:\n",
    "                ind2.append(i_x)\n",
    "        ind_len = [len(ind0), len(ind1), len(ind2)]\n",
    "        # print(f\"ind_len={ind_len}\")\n",
    "        # if we have enough words in the list, lets try to take a random\n",
    "        # number of words with certain score\n",
    "        if self.n_list >= self.n_to_learn:\n",
    "            n0 = self.n_to_learn\n",
    "            n1 = 0\n",
    "            n2 = 0\n",
    "            if len(ind1) > 0 and len(ind2) == 0:\n",
    "                n0 = round(self.n_to_learn*self.partition[0])\n",
    "                n1 = self.n_to_learn - n0\n",
    "                n2 = 0\n",
    "            elif len(ind1) > 0 and len(ind2) > 0:\n",
    "                n0 = round(self.n_to_learn*self.partition[0])\n",
    "                n1 = round(self.n_to_learn*self.partition[1])\n",
    "                n2 = self.n_to_learn - (n1 + n0)\n",
    "            # print(n0,n1,n2)\n",
    "            if ind_len[0] >= n0:\n",
    "                self.ind0_sampled = random.sample(ind0,n0)\n",
    "            else:\n",
    "                self.ind0_sampled = random.sample(ind0,ind_len[0])\n",
    "            if ind_len[1] >= n1:\n",
    "                self.ind1_sampled = random.sample(ind1,n1)\n",
    "            else:\n",
    "                self.ind1_sampled = random.sample(ind1,ind_len[1])\n",
    "            if ind_len[2] >= n2:\n",
    "                self.ind2_sampled = random.sample(ind2,n2)\n",
    "            else:\n",
    "                self.ind2_sampled = random.sample(ind2,ind_len[2])\n",
    "            # print(self.ind0_sampled, self.ind1_sampled, self.ind2_sampled)\n",
    "        else:\n",
    "            print(f\"\"\"Error: Requested too many words (n={self.n_to_learn}). \n",
    "                  List contains onlygit {self.n_list} words.\"\"\")\n",
    "    def CreateModel(self):\n",
    "        # prepare the llm model\n",
    "        import google.generativeai as genai\n",
    "\n",
    "        # read the api_key from a text file\n",
    "        with open(\"var.txt\",\"r\", encoding=\"utf-16\") as f:\n",
    "            var = f.read()\n",
    "        # connect to gemini model    \n",
    "        genai.configure(api_key=var)\n",
    "        self.model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
    "        \n",
    "    \n",
    "    def GenerateTask(self):\n",
    "        tasks_list= []\n",
    "        n = 3 # number of options to choose from\n",
    "        word_learn0 = [d.all_words[i]['word'] for i in d.ind0_sampled]\n",
    "        word_learn1 = [d.all_words[i]['word'] for i in d.ind1_sampled]\n",
    "        word_learn2 = [d.all_words[i]['word'] for i in d.ind2_sampled]\n",
    "        trans_learn0 = [d.all_words[i]['translation'] for i in d.ind0_sampled]\n",
    "        trans_learn1 = [d.all_words[i]['translation'] for i in d.ind1_sampled]\n",
    "        trans_learn2 = [d.all_words[i]['translation'] for i in d.ind2_sampled]\n",
    "        self.ind_sampled = d.ind0_sampled + d.ind1_sampled + d.ind2_sampled # combined\n",
    "        # get a verified list from gemini\n",
    "        prompt_text = f\"\"\"\n",
    "        Here is a list of {self.n_to_learn} words I want to learn in a form of quiz. After the words there is a list of their translations. \n",
    "        Return only a 2d list of size {self.n_to_learn}x{n} in json format, where for each translation propose {n} similar options to choose from in a quize. Don't return any extra text.\n",
    "        Expected return format: [['word1', 'right_translation1','option1_1','option1_2','option1_3'],['word2', 'right_translation2','option2_1','option2_2','option2_3'],...]\n",
    "        The words and translations: \"\"\" \n",
    "        # print(word_learn0)\n",
    "\n",
    "        chat_completion = self.model.generate_content(prompt_text +\n",
    "                                                           \", \".join(word_learn0)+\n",
    "                                                           \", \".join(word_learn1)+\n",
    "                                                           \", \".join(word_learn2)+ \n",
    "                                                           \" Translations: \" + \n",
    "                                                           \", \".join(trans_learn0) + \n",
    "                                                           \", \".join(trans_learn1) + \n",
    "                                                           \", \".join(trans_learn2))\n",
    "        raw_string = chat_completion.candidates[0].content.parts[0].text\n",
    "        # 1. Clean up the Markdown code block wrappers\n",
    "        clean_json = raw_string.strip().removeprefix('```json').removesuffix('```').strip()\n",
    "        # 2. Parse it with json.loads()\n",
    "        self.task_list_with_options = json.loads(clean_json)\n",
    "        # print(self.task_list_with_options)\n",
    "\n",
    "    def DoTask(self, if_genererate:bool=False, n_words:int = 5):\n",
    "        if if_genererate:\n",
    "            self.SelectWords(n_words)\n",
    "            self.GenerateTask()\n",
    "        for i in range(self.n_to_learn):\n",
    "            print(f\"Task {i+1}:\")\n",
    "            print(f\"Nederlands: {self.task_list_with_options[i][0]} \")\n",
    "            abcd = random.sample([1,2,3,4],4)\n",
    "            print(f\"1. {self.task_list_with_options[i][abcd[0]]} \")\n",
    "            print(f\"2. {self.task_list_with_options[i][abcd[1]]} \")\n",
    "            print(f\"3. {self.task_list_with_options[i][abcd[2]]} \")\n",
    "            print(f\"4. {self.task_list_with_options[i][abcd[3]]} \")\n",
    "            answer = input(\"Answer: \")\n",
    "            if answer == \"1\" and abcd[0] == 1:\n",
    "                print(\"Correct!\")\n",
    "                new_score = self.score_list[i]+0.1\n",
    "            elif answer == \"2\" and abcd[1] == 1:\n",
    "                print(\"Correct!\")\n",
    "                new_score = self.score_list[i]+0.1\n",
    "            elif answer == \"3\" and abcd[2] == 1:\n",
    "                print(\"Correct!\")\n",
    "                new_score = self.score_list[i]+0.1\n",
    "            elif answer == \"4\" and abcd[3] == 1:\n",
    "                print(\"Correct!\")\n",
    "                new_score = self.score_list[i]+0.1\n",
    "            else:\n",
    "                print(\"Wrong :(\")\n",
    "                print(f\"Correct answer: {self.task_list_with_options[i][1]}\")\n",
    "                new_score = self.score_list[i]-0.1\n",
    "            print(\"\\n\")\n",
    "            if new_score > 1.0:\n",
    "                new_score = 1.0\n",
    "            elif new_score < 0.0:\n",
    "                new_score = 0.0\n",
    "            self.words_list.update_score(self.ind_sampled[i],new_score)\n",
    "\n",
    "# from learner import MyLearner\n",
    "d = MyLearner(a)\n",
    "d.SelectWords(n=5)  \n",
    "d.CreateModel()\n",
    "# d.GenerateTask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d759816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1:\n",
      "Nederlands: Ze is goed in Frans. \n",
      "1. She knows French \n",
      "2. She speaks French \n",
      "3. She is good at French \n",
      "4. She likes French \n",
      "Correct!\n",
      "\n",
      "\n",
      "Task 2:\n",
      "Nederlands: Wij hopen op een snelle oplossing \n",
      "1. We found a solution \n",
      "2. We want a solution \n",
      "3. We hope a fast solution \n",
      "4. We need a solution \n",
      "Correct!\n",
      "\n",
      "\n",
      "Task 3:\n",
      "Nederlands: ik ben blij met de resultaten \n",
      "1. I changed the results \n",
      "2. I hate the results \n",
      "3. I am happy with the results \n",
      "4. I saw the results \n",
      "Correct!\n",
      "\n",
      "\n",
      "Task 4:\n",
      "Nederlands: gunstig \n",
      "1. amazing \n",
      "2. positive \n",
      "3. favourable \n",
      "4. lucky \n",
      "Wrong :(\n",
      "Correct answer: favourable\n",
      "\n",
      "\n",
      "Task 5:\n",
      "Nederlands: ongepast \n",
      "1. inappropriate \n",
      "2. rude \n",
      "3. unacceptable \n",
      "4. wrong \n",
      "Correct!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d.DoTask(if_genererate=True,n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b774e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyB82SFqZWri2-J_kkIpSDvMIaUXOJ1L3r8'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"var.txt\",\"r\", encoding=\"utf-16\") as f:\n",
    "    var = f.read()\n",
    "# var = \"AIzaSyB82SFqZWri2-J_kkIpSDvMIaUXOJ1L3r8\"\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6bd61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 43, 40, 26, 36]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.ind0_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "q = [random.random() for _ in range(10)]\n",
    "b = random.sample(q,10)\n",
    "sum(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
